p8105\_hw2\_rj2543
================
rj2543
October 1, 2018

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.0.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.6
    ## v tidyr   0.8.1     v stringr 1.3.1
    ## v readr   1.1.1     v forcats 0.3.0

    ## -- Conflicts ---------------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

problem 1
=========

This problem focuses on NYC Transit data; in particular, this CSV file contains information related to each entrance and exit for each subway station in NYC.

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

``` r
nycsubway = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%  #relative path instead of absolute path
  janitor::clean_names() #clean up variable names
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nycsubway
```

    ## # A tibble: 1,868 x 32
    ##    division line  station_name station_latitude station_longitu~ route1
    ##    <chr>    <chr> <chr>                   <dbl>            <dbl> <chr> 
    ##  1 BMT      4 Av~ 25th St                  40.7            -74.0 R     
    ##  2 BMT      4 Av~ 25th St                  40.7            -74.0 R     
    ##  3 BMT      4 Av~ 36th St                  40.7            -74.0 N     
    ##  4 BMT      4 Av~ 36th St                  40.7            -74.0 N     
    ##  5 BMT      4 Av~ 36th St                  40.7            -74.0 N     
    ##  6 BMT      4 Av~ 45th St                  40.6            -74.0 R     
    ##  7 BMT      4 Av~ 45th St                  40.6            -74.0 R     
    ##  8 BMT      4 Av~ 45th St                  40.6            -74.0 R     
    ##  9 BMT      4 Av~ 45th St                  40.6            -74.0 R     
    ## 10 BMT      4 Av~ 53rd St                  40.6            -74.0 R     
    ## # ... with 1,858 more rows, and 26 more variables: route2 <chr>,
    ## #   route3 <chr>, route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <int>, route9 <int>, route10 <int>, route11 <int>,
    ## #   entrance_type <chr>, entry <chr>, exit_only <chr>, vending <chr>,
    ## #   staffing <chr>, staff_hours <chr>, ada <lgl>, ada_notes <chr>,
    ## #   free_crossover <lgl>, north_south_street <chr>,
    ## #   east_west_street <chr>, corner <chr>, entrance_latitude <dbl>,
    ## #   entrance_longitude <dbl>, station_location <chr>,
    ## #   entrance_location <chr>

``` r
skimr::skim(nycsubway)
```

    ## Skim summary statistics
    ##  n obs: 1868 
    ##  n variables: 32 
    ## 
    ## -- Variable type:character ---------------------------------------------------------------------
    ##            variable missing complete    n min max empty n_unique
    ##           ada_notes    1793       75 1868   5  17     0       10
    ##              corner      32     1836 1868   1   4     0        8
    ##            division       0     1868 1868   3   3     0        3
    ##    east_west_street      35     1833 1868   6  24     0      352
    ##   entrance_location       0     1868 1868  22  23     0     1857
    ##       entrance_type       0     1868 1868   4   9     0        7
    ##               entry       0     1868 1868   2   3     0        2
    ##           exit_only    1812       56 1868   3   3     0        1
    ##                line       0     1868 1868   5  17     0       36
    ##  north_south_street      29     1839 1868   4  23     0      307
    ##              route1       0     1868 1868   1   2     0       24
    ##              route2     848     1020 1868   1   2     0       20
    ##              route3    1374      494 1868   1   2     0       18
    ##              route4    1547      321 1868   1   1     0       13
    ##              route5    1630      238 1868   1   1     0       12
    ##              route6    1741      127 1868   1   1     0        7
    ##              route7    1788       80 1868   1   2     0        7
    ##         staff_hours    1828       40 1868  16  33     0       16
    ##            staffing       0     1868 1868   4   6     0        4
    ##    station_location       0     1868 1868  20  23     0      472
    ##        station_name       0     1868 1868   4  39     0      356
    ##             vending       0     1868 1868   2   3     0        2
    ## 
    ## -- Variable type:integer -----------------------------------------------------------------------
    ##  variable missing complete    n mean   sd p0 p25 p50 p75 p100     hist
    ##   route10    1845       23 1868 3    0     3   3   3   3    3 <U+2581><U+2581><U+2581><U+2587><U+2581><U+2581><U+2581><U+2581>
    ##   route11    1845       23 1868 7    0     7   7   7   7    7 <U+2581><U+2581><U+2581><U+2587><U+2581><U+2581><U+2581><U+2581>
    ##    route8    1820       48 1868 2.98 1.94  1   1   4   5    5 <U+2587><U+2581><U+2581><U+2581><U+2581><U+2582><U+2581><U+2587>
    ##    route9    1840       28 1868 2.54 1.17  2   2   2   2    5 <U+2587><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2582>
    ## 
    ## -- Variable type:logical -----------------------------------------------------------------------
    ##        variable missing complete    n mean                      count
    ##             ada       0     1868 1868 0.25 FAL: 1400, TRU: 468, NA: 0
    ##  free_crossover       0     1868 1868 0.78 TRU: 1448, FAL: 420, NA: 0
    ## 
    ## -- Variable type:numeric -----------------------------------------------------------------------
    ##            variable missing complete    n   mean    sd     p0    p25
    ##   entrance_latitude       0     1868 1868  40.73 0.07   40.58  40.69
    ##  entrance_longitude       0     1868 1868 -73.86 3.42  -74.03 -73.99
    ##    station_latitude       0     1868 1868  40.73 0.07   40.58  40.69
    ##   station_longitude       0     1868 1868 -73.94 0.057 -74.03 -73.99
    ##     p50    p75   p100     hist
    ##   40.73  40.77  40.9  <U+2582><U+2582><U+2585><U+2587><U+2587><U+2582><U+2583><U+2582>
    ##  -73.96 -73.91  73.99 <U+2587><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581>
    ##   40.73  40.77  40.9  <U+2582><U+2582><U+2585><U+2587><U+2587><U+2582><U+2583><U+2582>
    ##  -73.96 -73.91 -73.76 <U+2583><U+2587><U+2585><U+2583><U+2582><U+2581><U+2581><U+2581>

``` r
nyc_subway = 
  select(nycsubway, line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%  # select required variables
  mutate(entry = (entry == "YES")) # convert "entry" variable from character to logical, yes = TRUE

nyc_subway
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu~ route1 route2
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr> 
    ##  1 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  2 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  3 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  4 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  5 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  6 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  7 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  8 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  9 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ## 10 4 Av~ 53rd St                  40.6            -74.0 R      <NA>  
    ## # ... with 1,858 more rows, and 13 more variables: route3 <chr>,
    ## #   route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>, route8 <int>,
    ## #   route9 <int>, route10 <int>, route11 <int>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

**The nyc\_subway dataset is derived from the original imported data which comes from "NYC\_Transit\_Subway\_Entrance\_And\_Exit\_Data.csv". This dataset contains line, station\_name, station\_latitude, station\_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance\_type, ada variables. The data cleaning steps are: 1) First import the data via the relative path instead of the absolute path in order to make code reproducible. 2) Second clean up variable names for future referrence. 3) Third select variables that are addressed in the problem requirement. 4) Fourth convert the "entry" variable from the original character structure to the logical structure ("YES" refers to "TRUE" while "NO" refers to "FALSE"). The resulting dataset has 1868 rows and 19 columns. These data are not tidy enough since data are somehow redundant.**

Answer the following questions using these data:

-   How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1; 125st 4/5); the distinct function may be useful here.

``` r
distinct(nyc_subway, line, station_name) %>% # identify distinct station by "line" and "station_name"
  nrow()
```

    ## [1] 465

-   How many stations are ADA compliant?

``` r
filter(nyc_subway, ada == TRUE) %>% 
  distinct(line, station_name) %>% # I guess the question means "distinct" stations?
  nrow()
```

    ## [1] 84

-   What proportion of station entrances / exits without vending allow entrance?

``` r
entry1 = filter(nycsubway, entry == "YES") # station entrances
entry2 = filter(nycsubway, entry == "YES" & vending == "NO") # entrances without vending

p1 = nrow(entry2)/nrow(entry1) # proportion of entrances without vending
p1
```

    ## [1] 0.0393611

``` r
exit1 = filter(nycsubway, exit_only == "Yes") # station exits
exit2 = filter(nycsubway, exit_only == "Yes" & vending == "NO") # exits without vending

p2 = nrow(exit2)/nrow(exit1) # proportion of exits without vending
p2
```

    ## [1] 0.8928571

Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

``` r
gather(nyc_subway, "route1":"route11", key = "route_number", value = "route_name")
```

    ## # A tibble: 20,548 x 10
    ##    line  station_name station_latitude station_longitu~ entry vending
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ##  2 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ##  3 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  4 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  5 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  6 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  7 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  8 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  9 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ## 10 4 Av~ 53rd St                  40.6            -74.0 TRUE  YES    
    ## # ... with 20,538 more rows, and 4 more variables: entrance_type <chr>,
    ## #   ada <lgl>, route_number <chr>, route_name <chr>

``` r
filter(nyc_subway, route1 == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 60

``` r
filter(nyc_subway, route1 == "A" & ada == TRUE) %>%
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 17

problem 2
=========

This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website. Please use the HealthyHarborWaterWheelTotals2018-7-28.xlsx version.

Read and clean the Mr. Trash Wheel sheet:

-   specify the sheet in the Excel file and to omit columns containing notes (using the range argument and cell\_cols() function)

-   use reasonable variable names

-   omit rows that do not include dumpster-specific data

-   round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

``` r
waterwheel = read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>% # omit column O which contains notes
  janitor::clean_names() %>% # clean up for reasonable variable names
  filter(!is.na(dumpster)) %>% # omit rows which are "month total"
  mutate(
    sports_balls = round(sports_balls), # round "sports_balls" to nearest integer
    sports_balls = as.integer(sports_balls) # convert sports balls from dbl to int
  )

waterwheel
```

    ## # A tibble: 285 x 14
    ##    dumpster month  year date                weight_tons volume_cubic_ya~
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71               13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52               14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76               18
    ## # ... with 275 more rows, and 8 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>

``` r
skimr::skim(waterwheel)
```

    ## Skim summary statistics
    ##  n obs: 285 
    ##  n variables: 14 
    ## 
    ## -- Variable type:character ---------------------------------------------------------------------
    ##  variable missing complete   n min max empty n_unique
    ##     month       0      285 285   3   9     0       12
    ## 
    ## -- Variable type:integer -----------------------------------------------------------------------
    ##      variable missing complete   n  mean    sd p0 p25 p50 p75 p100
    ##  sports_balls       0      285 285 12.66 10.32  0   5   8  18   56
    ##      hist
    ##  <U+2587><U+2583><U+2582><U+2582><U+2581><U+2581><U+2581><U+2581>
    ## 
    ## -- Variable type:numeric -----------------------------------------------------------------------
    ##            variable missing complete   n     mean       sd      p0
    ##           chip_bags       0      285 285  1920.56   970.9   330   
    ##     cigarette_butts       0      285 285 36103.86 35615.98 1000   
    ##            dumpster       0      285 285   143       82.42    1   
    ##       glass_bottles       0      285 285    27.98    19.04    2   
    ##        grocery_bags       0      285 285  1418.87   917.94   50   
    ##       homes_powered       0      285 285    41.93    25.6     0   
    ##     plastic_bottles       0      285 285  1969.05  1053.97  210   
    ##         polystyrene       0      285 285  2320.83  1209.83  320   
    ##  volume_cubic_yards       0      285 285    15.58     1.79    7   
    ##         weight_tons       0      285 285     3.28     0.78    0.96
    ##                year       0      285 285  2016.08     1.4  2014   
    ##       p25      p50      p75      p100     hist
    ##   1040     1840     2660      5085    <U+2587><U+2587><U+2586><U+2587><U+2586><U+2583><U+2581><U+2581>
    ##  12000    26000    46000    310000    <U+2587><U+2582><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581>
    ##     72      143      214       285    <U+2587><U+2587><U+2587><U+2587><U+2587><U+2587><U+2587><U+2587>
    ##     12       26       42       110    <U+2587><U+2587><U+2586><U+2583><U+2582><U+2581><U+2581><U+2581>
    ##    650     1240     2130      3750    <U+2587><U+2587><U+2585><U+2585><U+2585><U+2583><U+2582><U+2581>
    ##     30.5     50.67    60.33     93.67 <U+2587><U+2581><U+2582><U+2585><U+2587><U+2586><U+2582><U+2581>
    ##    980     1930     2670      5960    <U+2587><U+2587><U+2587><U+2587><U+2583><U+2582><U+2581><U+2581>
    ##   1250     2250     3150      6540    <U+2587><U+2587><U+2587><U+2587><U+2585><U+2582><U+2581><U+2581>
    ##     15       15       17        20    <U+2581><U+2581><U+2581><U+2581><U+2587><U+2581><U+2583><U+2581>
    ##      2.73     3.33     3.83      5.62 <U+2581><U+2582><U+2585><U+2587><U+2587><U+2585><U+2581><U+2581>
    ##   2015     2016     2017      2018    <U+2585><U+2587><U+2581><U+2586><U+2581><U+2586><U+2581><U+2587>
    ## 
    ## -- Variable type:POSIXct -----------------------------------------------------------------------
    ##  variable missing complete   n        min        max     median n_unique
    ##      date       0      285 285 2014-05-16 2018-07-28 2016-07-13      186

Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

``` r
precipitaion_2016 =  read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", skip = 1) %>% # use "skip" to overlook note "Precipitation (in)" in row 1
  janitor::clean_names() %>% # clean up variable names
  filter(!is.na(total) & !is.na(month)) %>% # omit rows without precipitation data
  mutate(year = 2016) %>% # add a "year" variable
  select(year, month, total) # let the data be more explicit

precipitaion_2016
```

    ## # A tibble: 12 x 3
    ##     year month total
    ##    <dbl> <dbl> <dbl>
    ##  1  2016     1  3.23
    ##  2  2016     2  5.32
    ##  3  2016     3  2.24
    ##  4  2016     4  1.78
    ##  5  2016     5  5.19
    ##  6  2016     6  3.2 
    ##  7  2016     7  6.09
    ##  8  2016     8  3.96
    ##  9  2016     9  4.53
    ## 10  2016    10  0.62
    ## 11  2016    11  1.47
    ## 12  2016    12  2.32

``` r
precipitaion_2017 =  read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", skip = 1) %>% # use "skip" to overlook note "Precipitation (in)" in row 1
  janitor::clean_names() %>% # clean up variable names
  filter(!is.na(total) & !is.na(month)) %>% # omit rows without precipitation data
  mutate(year = 2017) %>% # add a "year" variable
  select(year, month, total) # let the data be more explicit

precipitaion_2017
```

    ## # A tibble: 12 x 3
    ##     year month total
    ##    <dbl> <dbl> <dbl>
    ##  1  2017     1  2.34
    ##  2  2017     2  1.46
    ##  3  2017     3  3.57
    ##  4  2017     4  3.99
    ##  5  2017     5  5.64
    ##  6  2017     6  1.4 
    ##  7  2017     7  7.09
    ##  8  2017     8  4.44
    ##  9  2017     9  1.95
    ## 10  2017    10  0   
    ## 11  2017    11  0.11
    ## 12  2017    12  0.94

``` r
precipitation = left_join(precipitaion_2016, precipitaion_2017, by = "month") %>% # combine precipitation_2016 and precipitation_2017 using left join way
  janitor::clean_names() %>% # clean up variable names
  select(month, everything()) %>% # let common "month" variable to show at first
  mutate(month = month.name) # convert "month" to character variable

precipitation
```

    ## # A tibble: 12 x 5
    ##    month     year_x total_x year_y total_y
    ##    <chr>      <dbl>   <dbl>  <dbl>   <dbl>
    ##  1 January     2016    3.23   2017    2.34
    ##  2 February    2016    5.32   2017    1.46
    ##  3 March       2016    2.24   2017    3.57
    ##  4 April       2016    1.78   2017    3.99
    ##  5 May         2016    5.19   2017    5.64
    ##  6 June        2016    3.2    2017    1.4 
    ##  7 July        2016    6.09   2017    7.09
    ##  8 August      2016    3.96   2017    4.44
    ##  9 September   2016    4.53   2017    1.95
    ## 10 October     2016    0.62   2017    0   
    ## 11 November    2016    1.47   2017    0.11
    ## 12 December    2016    2.32   2017    0.94

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

**The waterwheel dataset is derived from "Mr. Trash Wheel" sheet in "HealthyHarborWaterWheelTotals2018-7-28.xlsx". This dataset contains 285 observations and each with 14 related characteristics: (dumpster, month, year, date, weight\_tons, volume\_cubic\_yards, plastic\_bottles, polystyrene, cigarette\_butts, glass\_bottles, grocery\_bags, chip\_bags, sports\_balls, homes\_powered). Here are several examples: **

    ## # A tibble: 6 x 14
    ##   dumpster month  year date                weight_tons volume_cubic_ya~
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ## 6        6 May    2014 2014-05-20 00:00:00        2.71               13
    ## # ... with 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <int>, homes_powered <dbl>

**The precipitation dataset is derived from "2016 Precipitation" and "2017 Precipitation" sheets in "HealthyHarborWaterWheelTotals2018-7-28.xlsx". This dataset contains 12 rows and 5 columns for observations. The key variables are: month, year\_x, total\_x, year\_y, total\_y. Here are several examples: **

    ## # A tibble: 6 x 5
    ##   month    year_x total_x year_y total_y
    ##   <chr>     <dbl>   <dbl>  <dbl>   <dbl>
    ## 1 January    2016    3.23   2017    2.34
    ## 2 February   2016    5.32   2017    1.46
    ## 3 March      2016    2.24   2017    3.57
    ## 4 April      2016    1.78   2017    3.99
    ## 5 May        2016    5.19   2017    5.64
    ## 6 June       2016    3.2    2017    1.4

**For available data, the total precipitation in 2017 is 32.93.**

**The median number of sports balls in a dumpster in 2016 is 26.**

Problem 3
=========

This problem uses the BRFSS data. DO NOT include this dataset in your local data directory; instead, load the data from the p8105.datasets package.

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
```

For this question:

-   format the data to use appropriate variable names;

-   focus on the “Overall Health” topic

-   exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation

-   structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data\_value in the original dataset)

-   create a new variable showing the proportion of responses that were “Excellent” or “Very Good”

``` r
data("brfss_smart2010")

brfss_smart2010 = janitor::clean_names(brfss_smart2010) %>% # clean up variable names
  filter(topic == "Overall Health") %>% # focus on "Overall Health" in "topic" variable
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>% # exclude unwanted variables
  spread(key = response, value = data_value) %>% # structure data to make values for "response" become variables
  janitor::clean_names() %>% # clean up new variable names
  select(year, locationabbr, locationdesc, excellent, very_good, good, fair, poor) %>% # arrange new variables
  mutate(proportion_great = excellent + very_good) # create variable for proportion of certain responses

brfss_smart2010
```

    ## # A tibble: 2,125 x 9
    ##     year locationabbr locationdesc excellent very_good  good  fair  poor
    ##    <int> <chr>        <chr>            <dbl>     <dbl> <dbl> <dbl> <dbl>
    ##  1  2002 AK           AK - Anchor~      27.9      33.7  23.8   8.6   5.9
    ##  2  2002 AL           AL - Jeffer~      18.5      30.9  32.7  12.1   5.9
    ##  3  2002 AR           AR - Pulask~      24.1      29.3  29.9  12.5   4.2
    ##  4  2002 AZ           AZ - Marico~      21.6      36.6  26.9  10.3   4.6
    ##  5  2002 AZ           AZ - Pima C~      26.6      30.1  31.9   7.5   3.9
    ##  6  2002 CA           CA - Los An~      22.7      29.8  28.7  14.3   4.5
    ##  7  2002 CO           CO - Adams ~      21.2      31.2  29    14.4   4.2
    ##  8  2002 CO           CO - Arapah~      25.5      35.2  29.3   8     2.1
    ##  9  2002 CO           CO - Denver~      22.2      27.1  36.6  11.1   3  
    ## 10  2002 CO           CO - Jeffer~      23.4      36.6  26.3  11.4   2.4
    ## # ... with 2,115 more rows, and 1 more variable: proportion_great <dbl>

Using this dataset, do or answer the following:

-   How many unique locations are included in the dataset? Is every state represented? What state is observed the most?

``` r
distinct(brfss_smart2010, brfss_smart2010$locationdesc) %>% 
  nrow() # unique locations
```

    ## [1] 404

``` r
distinct(brfss_smart2010, brfss_smart2010$locationabbr) %>% 
  nrow() # unique states
```

    ## [1] 51

``` r
abbrcount = count(brfss_smart2010, locationabbr)
abbrmax = max(abbrcount$n)
filter(abbrcount, n == abbrmax)
```

    ## # A tibble: 1 x 2
    ##   locationabbr     n
    ##   <chr>        <int>
    ## 1 NJ             146

``` r
# another approach: arrange "count" result first in descending order, then "head"
```

-   In 2002, what is the median of the “Excellent” response value?

``` r
excellent_2002 = filter(brfss_smart2010, year == 2002) %>% 
  select(excellent)

median(excellent_2002$excellent, na.rm = TRUE)
```

    ## [1] 23.6

-   Make a histogram of “Excellent” response values in the year 2002.

``` r
hist(excellent_2002$excellent, xlab = "Excellent proportion", main = "Histogram of Excellent proportion in 2002")
```

![](p8105_hw2_rj2543_files/figure-markdown_github/Excellent%20histogram-1.png)

-   Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

``` r
excellent_NY = filter(brfss_smart2010, locationdesc %in% c("NY - New York County", "NY - Queens County")) %>% 
  select(year, locationdesc, excellent) 

excellent_NY
```

    ## # A tibble: 18 x 3
    ##     year locationdesc         excellent
    ##    <int> <chr>                    <dbl>
    ##  1  2002 NY - New York County      27.9
    ##  2  2002 NY - Queens County        18.8
    ##  3  2003 NY - New York County      24.6
    ##  4  2003 NY - Queens County        16.4
    ##  5  2004 NY - New York County      27.2
    ##  6  2004 NY - Queens County        16.5
    ##  7  2005 NY - New York County      25.3
    ##  8  2005 NY - Queens County        15.7
    ##  9  2006 NY - New York County      28.8
    ## 10  2006 NY - Queens County        18.9
    ## 11  2007 NY - New York County      26.9
    ## 12  2007 NY - Queens County        13.1
    ## 13  2008 NY - New York County      30  
    ## 14  2008 NY - Queens County        17.6
    ## 15  2009 NY - New York County      30.4
    ## 16  2009 NY - Queens County        17.5
    ## 17  2010 NY - New York County      25.8
    ## 18  2010 NY - Queens County        21.2

``` r
ggplot(excellent_NY, aes(x = year, y = excellent)) + 
  geom_point(aes(color = locationdesc))
```

![](p8105_hw2_rj2543_files/figure-markdown_github/Excellent%20scatterplot-1.png)
