---
title: "p8105_hw2_rj2543"
author: "rj2543"
date: "October 1, 2018"
output: github_document
---

```{r set up}
library(tidyverse)
library(readxl)
```


# problem 1

This problem focuses on NYC Transit data; in particular, this CSV file contains information related to each entrance and exit for each subway station in NYC.

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

```{r data import}
nycsubway = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%  #relative path instead of absolute path
  janitor::clean_names() #clean up variable names

nycsubway
skimr::skim(nycsubway)
```

```{r data clean}
nyc_subway = 
  select(nycsubway, line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%  # select required variables
  mutate(entry = (entry == "YES")) # convert "entry" variable from character to logical, yes = TRUE

nyc_subway
```


Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

**The nyc_subway dataset is derived from the original imported data which comes from "NYC_Transit_Subway_Entrance_And_Exit_Data.csv". This dataset contains `r names(nyc_subway)` variables. The data cleaning steps are: 1) First import the data via the relative path instead of the absolute path in order to make code reproducible. 2) Second clean up variable names for future referrence. 3) Third select variables that are addressed in the problem requirement. 4) Fourth convert the "entry" variable from the original character structure to the logical structure ("YES" refers to "TRUE" while "NO" refers to "FALSE"). The resulting dataset has `r nrow(nyc_subway)` rows and `r ncol(nyc_subway)` columns. These data are not tidy enough since data are somehow redundant.**

Answer the following questions using these data:

* How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1; 125st 4/5); the distinct function may be useful here.

```{r dinstint stations}
distinct(nyc_subway, line, station_name) %>% # identify distinct station by "line" and "station_name"
  nrow()
```

* How many stations are ADA compliant?

```{r ADA compliant}
filter(nyc_subway, ada == TRUE) %>% 
  distinct(line, station_name) %>% # I guess the question means "distinct" stations?
  nrow()
```


* What proportion of station entrances / exits without vending allow entrance?

```{r proportion without vending}
entry1 = filter(nycsubway, entry == "YES") # station entrances
entry2 = filter(nycsubway, entry == "YES" & vending == "NO") # entrances without vending

p1 = nrow(entry2)/nrow(entry1) # proportion of entrances without vending
p1

exit1 = filter(nycsubway, exit_only == "Yes") # station exits
exit2 = filter(nycsubway, exit_only == "Yes" & vending == "NO") # exits without vending

p2 = nrow(exit2)/nrow(exit1) # proportion of exits without vending
p2
```


Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

```{r reformat}
gather(nyc_subway, "route1":"route11", key = "route_number", value = "route_name")

filter(nyc_subway, route1 == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()

filter(nyc_subway, route1 == "A" & ada == TRUE) %>%
  distinct(line, station_name) %>% 
  nrow()
```


# problem 2
This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website. Please use the  HealthyHarborWaterWheelTotals2018-7-28.xlsx version.

Read and clean the Mr. Trash Wheel sheet:

* specify the sheet in the Excel file and to omit columns containing notes (using the range argument and cell_cols() function)

* use reasonable variable names

* omit rows that do not include dumpster-specific data

* round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r TRASHWHEEL import and clean}
waterwheel = read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>% # omit column O which contains notes
  janitor::clean_names() %>% # clean up for reasonable variable names
  filter(!is.na(dumpster)) %>% # omit rows which are "month total"
  mutate(
    sports_balls = round(sports_balls), # round "sports_balls" to nearest integer
    sports_balls = as.integer(sports_balls) # convert sports balls from dbl to int
  )

waterwheel
skimr::skim(waterwheel)
```

Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

```{r 2016 import and clean}
precipitaion_2016 =  read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", skip = 1) %>% # use "skip" to overlook note "Precipitation (in)" in row 1
  janitor::clean_names() %>% # clean up variable names
  filter(!is.na(total) & !is.na(month)) %>% # omit rows without precipitation data
  mutate(year = 2016) %>% # add a "year" variable
  select(year, month, total) # let the data be more explicit

precipitaion_2016
```

```{r 2017 import and clean}
precipitaion_2017 =  read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", skip = 1) %>% # use "skip" to overlook note "Precipitation (in)" in row 1
  janitor::clean_names() %>% # clean up variable names
  filter(!is.na(total) & !is.na(month)) %>% # omit rows without precipitation data
  mutate(year = 2017) %>% # add a "year" variable
  select(year, month, total) # let the data be more explicit

precipitaion_2017
```

```{r 2016 and 2017 combine}
precipitation = left_join(precipitaion_2016, precipitaion_2017, by = "month") %>% # combine precipitation_2016 and precipitation_2017 using left join way
  janitor::clean_names() %>% # clean up variable names
  select(month, everything()) %>% # let common "month" variable to show at first
  mutate(month = month.name) # convert "month" to character variable

precipitation
```


Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

**The waterwheel dataset is derived from "Mr. Trash Wheel" sheet in "HealthyHarborWaterWheelTotals2018-7-28.xlsx". This dataset contains `r nrow(waterwheel)` observations and each with `r ncol(waterwheel)` related characteristics: (`r names(waterwheel)`). Here are several examples: **
```{r waterwheel example, echo = FALSE}
head(waterwheel)
```

**The precipitation dataset is derived from "2016 Precipitation" and "2017 Precipitation" sheets in "HealthyHarborWaterWheelTotals2018-7-28.xlsx". This dataset contains `r nrow(precipitation)` rows and `r ncol(precipitation)` columns for observations. The key variables are: `r names(precipitation)`. Here are several examples: **
```{r precipitation example, echo = FALSE}
head(precipitation)
```

**For available data, the total precipitation in 2017 is `r sum(precipitation$total_y, na.rm = TRUE)`.**

```{r waterwheel 2016 sports balls, include = FALSE}
sportsballs_2016 = filter(waterwheel, year == 2016) %>% 
  select(year, sports_balls)
```

**The median number of sports balls in a dumpster in 2016 is `r median(sportsballs_2016$sports_balls)`.**

# Problem 3

This problem uses the BRFSS data. DO NOT include this dataset in your local data directory; instead, load the data from the p8105.datasets package.

```{r load package}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
```


For this question:

* format the data to use appropriate variable names;

* focus on the “Overall Health” topic

* exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation

* structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset)

* create a new variable showing the proportion of responses that were “Excellent” or “Very Good”

```{r data tidy}
data("brfss_smart2010")

brfss_smart2010 = janitor::clean_names(brfss_smart2010) %>% # clean up variable names
  filter(topic == "Overall Health") %>% # focus on "Overall Health" in "topic" variable
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>% # exclude unwanted variables
  spread(key = response, value = data_value) %>% # structure data to make values for "response" become variables
  janitor::clean_names() %>% # clean up new variable names
  select(year, locationabbr, locationdesc, excellent, very_good, good, fair, poor) %>% # arrange new variables
  mutate(proportion_great = excellent + very_good) # create variable for proportion of certain responses

brfss_smart2010
```


Using this dataset, do or answer the following:

* How many unique locations are included in the dataset? Is every state represented? What state is observed the most?

```{r location}
distinct(brfss_smart2010, brfss_smart2010$locationdesc) %>% 
  nrow() # unique locations

distinct(brfss_smart2010, brfss_smart2010$locationabbr) %>% 
  nrow() # unique states

abbrcount = count(brfss_smart2010, locationabbr)
abbrmax = max(abbrcount$n)
filter(abbrcount, n == abbrmax)
# another approach: arrange "count" result first in descending order, then "head"
```


* In 2002, what is the median of the “Excellent” response value?

```{r Excellent median}
excellent_2002 = filter(brfss_smart2010, year == 2002) %>% 
  select(excellent)

median(excellent_2002$excellent, na.rm = TRUE)
```


* Make a histogram of “Excellent” response values in the year 2002.

```{r Excellent histogram}
hist(excellent_2002$excellent, xlab = "Excellent proportion", main = "Histogram of Excellent proportion in 2002")
```


* Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r Excellent scatterplot}
excellent_NY = filter(brfss_smart2010, locationdesc %in% c("NY - New York County", "NY - Queens County")) %>% 
  select(year, locationdesc, excellent) 

excellent_NY
ggplot(excellent_NY, aes(x = year, y = excellent)) + 
  geom_point(aes(color = locationdesc))
```

